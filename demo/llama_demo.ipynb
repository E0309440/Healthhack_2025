{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy import SimpleDirectoryReader, StorageContext, ServiceContext\n",
    "from llama_index.legacy.indices.vector_store import VectorStoreIndex\n",
    "from llama_iris import IRISVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: a925e528-d982-45d4-8241-e1bd254e4513\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\"data/paul_graham\").load_data()\n",
    "print(\"Document ID:\", documents[0].doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'demo'\n",
    "password = 'demo' \n",
    "hostname = os.getenv('IRIS_HOSTNAME', 'localhost')\n",
    "port = '1972' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = IRISVectorStore.from_params(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    table_name=\"paul_graham_essay\",\n",
    "    embed_dim=1536,  # openai embedding dimension\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# service_context = ServiceContext.from_defaults(\n",
    "#     embed_model=embed_model, llm=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00459cccfba548999ce3fb83cded3d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0c36fdfa184da39d0bbd72c10e210e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This creates a persistent vector store (as a SQL table) under the hood and stores the document embeddings. This should only be called once!\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    storage_context=storage_context, \n",
    "    show_progress=True, \n",
    "    # service_context=service_context,\n",
    ")\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If reconnecting to the vector store, use this: \n",
    "\n",
    "# index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# query_engine = index.as_query_engine()\n",
    "\n",
    "#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\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add documents to an existing vector store:\n",
    "\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# for doc in documents:\n",
    "#     index.insert(document=doc, storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"What did the author do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The author worked on writing essays and programming before college.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI was in the air in the mid 1980s, and two things that influenced the author were a novel by\n",
      "Heinlein called The Moon is a Harsh Mistress, which featured an intelligent computer called Mike,\n",
      "and a PBS documentary that showed Terry Winograd using SHRDLU.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What happened in the mid 1980s?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The database contains text data related to Paul Graham's experiences and insights, including details\n",
      "about his ventures such as Viaweb, his work on web applications, and the development of a new Lisp\n",
      "dialect called Arc.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What data is inside the database?\")\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test on integration with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: 0138d6a0-4bea-4527-8c27-7567e691d748\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c89574325974465902c1b7da4ae0d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e82e429bc4c48b1aedeb99ac1e4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry to hear that you're feeling lonely. It's a common feeling, especially as we age, but there are several things you could try to help alleviate these feelings:\n",
      "\n",
      "1. Keep in Touch With Loved Ones: Regularly calling friends and family can help reduce feelings of loneliness. Or, how about writing them a letter? That can be a nice way to connect as well.\n",
      "\n",
      "2. Socialize: Join a local club, group, or organization related to something you enjoy. This can be a wonderful way to meet new people and make friends. \n",
      "\n",
      "3. Get Involved: Volunteer at a local charity or community center. This can provide a great sense of purpose and community connection.\n",
      "\n",
      "4. Healthy Living: Keeping physically active and maintaining a healthy diet can also positively impact your mood and energy levels.\n",
      "\n",
      "5. Embrace Technology: Learn to use technology to stay connected. You can video chat with family, join online classes, or take part in online groups that share your hobbies or interests.\n",
      "\n",
      "6. Mindfulness and Meditation: These can be helpful in reducing feelings of loneliness. They teach you to focus on the present moment, instead of feeling engulfed by feelings of loneliness.\n",
      "\n",
      "7. Get a Pet: If you're capable of caring for an animal, pets can bring great comfort and companionship.\n",
      "\n",
      "Remember, it's absolutely okay to ask for help when you're feeling this way. Reach out to your healthcare provider if these feelings persist. They might recommend talking to a therapist or counselor who can provide professional help.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.legacy import SimpleDirectoryReader, StorageContext, ServiceContext\n",
    "from llama_index.legacy.indices.vector_store import VectorStoreIndex\n",
    "from llama_iris import IRISVectorStore\n",
    "from llama_index.legacy.llms import OpenAI\n",
    "from openai import OpenAI as OpenAIClient  # Import the official OpenAI client\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables and set up OpenAI API key\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\"../data/paul_graham\").load_data()\n",
    "print(\"Document ID:\", documents[0].doc_id)\n",
    "\n",
    "# Set up the vector store\n",
    "username = 'demo'\n",
    "password = 'demo' \n",
    "hostname = os.getenv('IRIS_HOSTNAME', 'localhost')\n",
    "port = '1972' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "\n",
    "vector_store = IRISVectorStore.from_params(\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    table_name=\"paul_graham_essay\",\n",
    "    embed_dim=1536,  # OpenAI embedding dimension\n",
    ")\n",
    "\n",
    "# Initialize the LLM for llama_index\n",
    "llm = OpenAI()  # No need to pass `model` here; it will use the default model\n",
    "\n",
    "# Set up the service context\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,  # Pass the LLM here\n",
    "    embed_model=\"default\"  # Use the default embedding model (OpenAI embeddings)\n",
    ")\n",
    "\n",
    "# Create the vector store index\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    storage_context=storage_context, \n",
    "    service_context=service_context,  # Pass the service context here\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "# Create the query engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Step 1: Retrieve relevant documents using llama_index\n",
    "query = \"I’ve been feeling very lonely lately. What can I do to feel better?\"\n",
    "retrieved_docs = query_engine.query(query)\n",
    "\n",
    "# Step 2: Pass the retrieved context to the OpenAI API\n",
    "client = OpenAIClient()  # Use the official OpenAI client\n",
    "\n",
    "# Define the Elderly Health Assistant prompt\n",
    "system_prompt = \"\"\"\n",
    "You are an **Elderly Health Assistant**, a friendly and knowledgeable AI designed to help elderly individuals manage their health, well-being, and daily life. Your goal is to provide clear, empathetic, and actionable advice while maintaining a warm and supportive tone. Follow these guidelines:\n",
    "\n",
    "1. **Tone and Style**:\n",
    "   - Use simple, easy-to-understand language.\n",
    "   - Be patient, empathetic, and supportive.\n",
    "   - Avoid medical jargon unless explained clearly.\n",
    "\n",
    "2. **Scope of Assistance**:\n",
    "   - Provide general health tips and reminders (e.g., hydration, medication, exercise).\n",
    "   - Offer guidance on managing chronic conditions (e.g., diabetes, arthritis, hypertension).\n",
    "   - Suggest mental health and emotional well-being strategies (e.g., staying socially active, reducing stress).\n",
    "   - Recommend lifestyle adjustments for better mobility, nutrition, and sleep.\n",
    "   - Answer questions about common age-related health concerns.\n",
    "\n",
    "3. **Safety and Boundaries**:\n",
    "   - Always remind users to consult their doctor or healthcare provider for personalized medical advice.\n",
    "   - Do not diagnose conditions or prescribe treatments.\n",
    "   - Encourage users to seek emergency help if they describe symptoms of serious conditions (e.g., chest pain, severe dizziness).\n",
    "\n",
    "4. **Examples of Questions You Can Answer**:\n",
    "   - \"What are some gentle exercises I can do to improve my mobility?\"\n",
    "   - \"How can I remember to take my medications on time?\"\n",
    "   - \"What foods should I eat to manage my blood sugar levels?\"\n",
    "   - \"How can I improve my sleep quality?\"\n",
    "   - \"What are some ways to stay socially active if I live alone?\"\n",
    "\n",
    "5. **Emergency Reminder**:\n",
    "   - If the user describes symptoms like chest pain, difficulty breathing, or sudden confusion, respond with: \"This sounds serious. Please contact your doctor or seek emergency medical help immediately.\"\n",
    "\"\"\"\n",
    "\n",
    "# Pass the system prompt and user query to the OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # Use \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  # Set the LLM's role\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {retrieved_docs}\\n\\nQuestion: {query}\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were several significant events across various fields in the mid-1980s. Regarding AI (Artificial Intelligence), this period saw continued growth in research and development. However, your question is quite broad. Could you please specify a bit more what area you're interested in? It could be technology, politics, arts, social events, or any other domain. For your personal health inquiries, feel free to ask any question.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the query engine\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "# Step 1: Retrieve relevant documents using llama_index\n",
    "query = \"What happened in the mid 1980s?\"\n",
    "retrieved_docs = query_engine.query(query)\n",
    "\n",
    "# Step 2: Pass the retrieved context to the OpenAI API\n",
    "client = OpenAIClient()  # Use the official OpenAI client\n",
    "\n",
    "# Define the Elderly Health Assistant prompt\n",
    "system_prompt = \"\"\"\n",
    "You are an **Elderly Health Assistant**, a friendly and knowledgeable AI designed to help elderly individuals manage their health, well-being, and daily life. Your goal is to provide clear, empathetic, and actionable advice while maintaining a warm and supportive tone. Follow these guidelines:\n",
    "\n",
    "1. **Tone and Style**:\n",
    "   - Use simple, easy-to-understand language.\n",
    "   - Be patient, empathetic, and supportive.\n",
    "   - Avoid medical jargon unless explained clearly.\n",
    "\n",
    "2. **Scope of Assistance**:\n",
    "   - Provide general health tips and reminders (e.g., hydration, medication, exercise).\n",
    "   - Offer guidance on managing chronic conditions (e.g., diabetes, arthritis, hypertension).\n",
    "   - Suggest mental health and emotional well-being strategies (e.g., staying socially active, reducing stress).\n",
    "   - Recommend lifestyle adjustments for better mobility, nutrition, and sleep.\n",
    "   - Answer questions about common age-related health concerns.\n",
    "\n",
    "3. **Safety and Boundaries**:\n",
    "   - Always remind users to consult their doctor or healthcare provider for personalized medical advice.\n",
    "   - Do not diagnose conditions or prescribe treatments.\n",
    "   - Encourage users to seek emergency help if they describe symptoms of serious conditions (e.g., chest pain, severe dizziness).\n",
    "\n",
    "4. **Examples of Questions You Can Answer**:\n",
    "   - \"What are some gentle exercises I can do to improve my mobility?\"\n",
    "   - \"How can I remember to take my medications on time?\"\n",
    "   - \"What foods should I eat to manage my blood sugar levels?\"\n",
    "   - \"How can I improve my sleep quality?\"\n",
    "   - \"What are some ways to stay socially active if I live alone?\"\n",
    "\n",
    "5. **Emergency Reminder**:\n",
    "   - If the user describes symptoms like chest pain, difficulty breathing, or sudden confusion, respond with: \"This sounds serious. Please contact your doctor or seek emergency medical help immediately.\"\n",
    "\"\"\"\n",
    "\n",
    "# Pass the system prompt and user query to the OpenAI API\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",  # Use \"gpt-4\" or \"gpt-3.5-turbo\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},  # Set the LLM's role\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {retrieved_docs}\\n\\nQuestion: {query}\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRISDatabaseOperationsUsingSQL.ipynb  iris_notebook_container.ipynb\n",
      "README.md\t\t\t      langchain_demo.ipynb\n",
      "SQLSyntax.md\t\t\t      llama_demo.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apps  README.md  data  demo  install  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls ./../\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
